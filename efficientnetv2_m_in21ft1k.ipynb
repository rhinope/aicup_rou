{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install monai\n",
    "# !pip3 install -U Setuptools\n",
    "# !pip install torchvision\n",
    "# !pip install git+https://github.com/qubvel/segmentation_models.pytorch\n",
    "# !pip install adabelief-pytorch==0.2.0\n",
    "\n",
    "# !pip install ipywidgets widgetsnbextension\n",
    "# !jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define shape_to_mask function\n",
    "\n",
    "參照老師"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_to_mask(\n",
    "    img_shape, points, shape_type=None, line_width=10, point_size=5\n",
    "):\n",
    "    mask = np.zeros(img_shape[:2], dtype=np.uint8) \n",
    "    mask = PIL.Image.fromarray(mask) \n",
    "    \n",
    "    draw = PIL.ImageDraw.Draw(mask) \n",
    "\n",
    "    xy = [tuple(point) for point in points] \n",
    "    \n",
    "    if shape_type == \"circle\":\n",
    "        assert len(xy) == 2, \"Shape of shape_type = circle must have 2 points\"\n",
    "        (cx, cy), (px, py) = xy\n",
    "        d = math.sqrt((cx - px) ** 2 + (cy - py) ** 2)\n",
    "        draw.ellipse([cx - d, cy - d, cx + d, cy + d], outline=1, fill=1) \n",
    "    elif shape_type == \"rectangle\":\n",
    "        assert len(xy) == 2, \"Shape of shape_type=rectangle must have 2 points\"\n",
    "        draw.rectangle(xy, outline=1, fill=1)\n",
    "    elif shape_type == \"line\":\n",
    "        assert len(xy) == 2, \"Shape of shape_type=line must have 2 points\"\n",
    "        draw.line(xy=xy, fill=1, width=line_width)\n",
    "    elif shape_type == \"linestrip\":\n",
    "        draw.line(xy=xy, fill=1, width=line_width)\n",
    "    elif shape_type == \"point\":\n",
    "        assert len(xy) == 1, \"Shape of shape_type=point must have 1 points\"\n",
    "        cx, cy = xy[0]\n",
    "        r = point_size\n",
    "        draw.ellipse([cx - r, cy - r, cx + r, cy + r], outline=1, fill=1)\n",
    "    else:\n",
    "        assert len(xy) > 2, \"Polygon must have points more than 2\" \n",
    "        draw.polygon(xy=xy, outline=1, fill=1)\n",
    "    mask = np.array(mask, dtype=bool)\n",
    "    return mask "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set process folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path\n",
    "folder_path = \"{YOUR PATH}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Visualize Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    for i, (name, image) in enumerate(images.items()):  \n",
    "        plt.subplot(1, n, i + 1)  \n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing all json file in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "os.makedirs(folder_path.replace(\"Train_Annotations\", \"Train_Annotations_png\"))\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if 'json' in filename:\n",
    "        # Read in all all the data from the CSV file      \n",
    "        json_path = os.path.join(folder_path, filename)       \n",
    "        \n",
    "        write_msk_img_name = filename.replace(\"json\",\"png\")\n",
    "        write_folder_path = folder_path.replace(\"Train_Annotations\",\"Train_Annotations_png\")\n",
    "        \n",
    "        img_path = folder_path.replace(\"/Train_Annotations/\",\"/Train_Images/\") + filename.replace(\"json\",\"jpg\")\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        #Read Json file\n",
    "        with open(json_path, \"r\",encoding=\"utf-8\") as f:\n",
    "            dj = json.load(f)\n",
    "\n",
    "        temp_mask_img = np.zeros([dj['imageHeight'], dj['imageWidth']],dtype=np.uint8)\n",
    "\n",
    "        #Plot each mask into mask_img\n",
    "        for i in range(len(dj['shapes'])):\n",
    "            mask = shape_to_mask((dj['imageHeight'],dj['imageWidth']), dj['shapes'][i]['points'], shape_type=dj['shapes'][i]['shape_type'],line_width=1, point_size=1)            \n",
    "            temp_mask_img = temp_mask_img + mask.astype(int) \n",
    "        temp_mask_img = (temp_mask_img>0).astype(int)\n",
    "        \n",
    "        print(f\"temp_mask_img.range is {temp_mask_img.max()} to {temp_mask_img.min()}\")\n",
    "        # Save the file\n",
    "        cv2.imwrite(write_folder_path + write_msk_img_name, temp_mask_img*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tempfile\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import setuptools\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "\n",
    "\n",
    "import monai\n",
    "from monai.data import create_test_image_2d, list_data_collate, decollate_batch\n",
    "from monai.inferers import sliding_window_inference, SimpleInferer\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AddChanneld,\n",
    "    AsDiscrete,\n",
    "    Compose,  \n",
    "    LoadImaged,\n",
    "    RandRotate90d,\n",
    "    ScaleIntensityd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    AsChannelFirstd,\n",
    "    Resized,\n",
    "    # RandScaleCropd,\n",
    "    RandRotated,\n",
    "    SaveImage,\n",
    "    # RandSpatialCropd,\n",
    "    Resize,\n",
    ")\n",
    "from adabelief_pytorch import AdaBelief\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monai config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monai.config.print_config()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('../SEG_Train_Datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Data folder\n",
    "data_path = './SEG_Train_Datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train files\n",
    "for_test = 256\n",
    "\n",
    "\n",
    "tempdir = data_path + \"Train_Images\"\n",
    "train_images = sorted(glob.glob(os.path.join(tempdir, \"*.jpg\")))\n",
    "\n",
    "tempdir = data_path + \"Train_Annotations_png\"\n",
    "train_segs = sorted(glob.glob(os.path.join(tempdir, \"*.png\")))\n",
    "\n",
    "\n",
    "print(\" {} train_images and {} train_segs\".format(len(train_images[for_test:]), len(train_segs[for_test:])))\n",
    "\n",
    "\n",
    "train_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(train_images[for_test:], train_segs[for_test:])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(train_images[:for_test], train_segs[:for_test])]\n",
    "print(\" {} val_images and {} val_segs\".format(len(train_images[:for_test]), len(train_segs[:for_test])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Trasform for image and segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, length = 800, 800\n",
    "\n",
    "\n",
    "# define transforms for image and segmentation\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "        AddChanneld(keys=[\"seg\"]),        \n",
    "        AsChannelFirstd(keys=[\"img\"]),\n",
    "        ScaleIntensityd(keys=[\"img\", \"seg\"]),\n",
    "        RandRotated(keys=[\"img\", \"seg\"],range_x= 3.14),\n",
    "        Resized(keys=[\"img\", \"seg\"], spatial_size=[width, length]),\n",
    "        RandRotate90d(keys=[\"img\", \"seg\"], prob=0.3, spatial_axes=[0, 1]),\n",
    "        EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "        AddChanneld(keys=[\"seg\"]),        \n",
    "        AsChannelFirstd(keys=[\"img\"]),\n",
    "        ScaleIntensityd(keys=[\"img\", \"seg\"]),\n",
    "        Resized(keys=[\"img\"], spatial_size=[width, length]),\n",
    "        EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check and visualize the transform results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset, data loader\n",
    "check_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "print(type(check_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataLoader for train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size\n",
    "batch_size = 16\n",
    "# create a training data loader\n",
    "train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size= batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=list_data_collate,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "# create a validation data loader\n",
    "val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size= batch_size, collate_fn=list_data_collate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define metric and post-processing\n",
    "\n",
    "1. Monai有Dice的metrics與loss\n",
    "2. define output transform (老師提供)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
    "post_trans = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0, 1, 2, 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Visualize Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image, cmap= 'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "#### create UNet, DiceLoss and Adam optimizer\n",
    "\n",
    "> 這部分由老師上課提供的範例程式做修改\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'tf_efficientnetv2_m_in21ft1k_ver3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_params=dict(\n",
    "    pooling='avg',           \n",
    "    dropout=0.4,              \n",
    "    activation=None,      \n",
    "    classes=1,               \n",
    ")\n",
    "\n",
    "encodes = 'tu-tf_efficientnetv2_m_in21ft1k'\n",
    "model = smp.DeepLabV3Plus(encodes, aux_params=aux_params)\n",
    "model = torch.nn.DataParallel(model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdaBelief(model.parameters(), lr=1e-4, eps=1e-16, betas=(0.9, 0.98923), weight_decouple = True, rectify = False, weight_decay = 1e-4)\n",
    "loss_function = monai.losses.DiceLoss(sigmoid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### start a typical PyTorch training\n",
    "total_epochs = 350\n",
    "val_interval = 1\n",
    "best_metric = 100   #best\n",
    "best_metric_epoch = -1  #best\n",
    "epoch_loss_values = list()   #empty list = []\n",
    "metric_values = list()\n",
    "\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{total_epochs}\")\n",
    "\n",
    "    # 開始訓練\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "\n",
    "    for iters, batch_data in enumerate(train_loader):\n",
    "\n",
    "        step += 1\n",
    "        epoch_len = len(train_ds) // train_loader.batch_size   \n",
    "        print(f\" {step}/{epoch_len}\" , end='\\r')\n",
    "\n",
    "        inputs, labels = batch_data[\"img\"].to(device), batch_data[\"seg\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()     \n",
    "        outputs, label = model(inputs)    \n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    local_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())    \n",
    "    print(\"\\n\", f\"{local_time} epoch {epoch + 1} training average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_images = None\n",
    "            val_labels = None\n",
    "            val_outputs = None\n",
    "            steps = 0\n",
    "            loss_val = 0\n",
    "\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data[\"img\"].to(device), val_data[\"seg\"].to(device)\n",
    "                \n",
    "#                 roi_size = (800, 800)\n",
    "#                 sw_batch_size = 32\n",
    "#                 # predict\n",
    "#                 val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model) \n",
    "                \n",
    "                val_outputs, val_out_label = model(val_images) #forward\n",
    "                val_outputs = Resize([-1, 1716, 942])(val_outputs)\n",
    "\n",
    "                val_loss = monai.losses.DiceLoss(sigmoid=True)(val_outputs, val_labels)\n",
    "                loss_val += val_loss\n",
    "                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]                \n",
    "\n",
    "                # compute metric for current iteration\n",
    "                if  steps < 3:\n",
    "                    print(\"val loss\", val_loss)\n",
    "                    visualize( \n",
    "                        image=val_images[0].cpu().permute(1,2,0), \n",
    "                        ground_truth_mask=val_labels[0].cpu().permute(1,2,0), \n",
    "                        predicted_mask=val_outputs[0].cpu().permute(1,2,0)\n",
    "\n",
    "                    )  \n",
    "                steps += 1\n",
    "            # aggregate the final mean dice result\n",
    "            print(\"val_loss = \", loss_val / steps)\n",
    "            val_loss_mean = loss_val / steps\n",
    "\n",
    "            # reset the status for next validation round\n",
    "            metric_values.append(val_loss_mean)\n",
    "\n",
    "            if val_loss_mean < best_metric:\n",
    "                best_metric = val_loss_mean\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), f\"{save_path}.pth\")\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                \"current epoch: {} current val mean dice loss: {:.4f} best val mean dice loss: {:.4f} at epoch {}\".format(\n",
    "                    epoch + 1, val_loss_mean, best_metric, best_metric_epoch\n",
    "                )\n",
    "            )\n",
    "\n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 讀取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"{}.pth\".format(save_path)))\n",
    "# model.load_state_dict(torch.load(\"rou.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "dice_metric.reset()\n",
    "with torch.no_grad():\n",
    "    val_images = None\n",
    "    val_labels = None\n",
    "    val_outputs = None\n",
    "    for val_data in val_loader:\n",
    "        val_images, val_labels = val_data[\"img\"].to(device), val_data[\"seg\"].to(device)\n",
    "\n",
    "#         roi_size = (800, 800)\n",
    "#         sw_batch_size = 4\n",
    "#         val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model) \n",
    "\n",
    "        val_outputs, val_out_label = model(val_images) #forward\n",
    "        val_outputs = Resize([-1, 1716, 942])(val_outputs)\n",
    "        val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]                \n",
    "              \n",
    "        # compute metric for current iteration\n",
    "        dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "        print(dice_metric.aggregate())\n",
    "    # aggregate the final mean dice result\n",
    "    metric = dice_metric.aggregate().item()\n",
    "    print(\"dice metric = \", metric)\n",
    "    # reset the status for next validation round\n",
    "    dice_metric.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 上傳結果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdir = \"./Public_Image/\"\n",
    "test_images = sorted(glob.glob(os.path.join(tempdir, \"*.jpg\")))\n",
    "\n",
    "\n",
    "print(\" {} test_images\".format(len(test_images)))\n",
    "\n",
    "test_files = [{\"img\": img} for img in test_images[:]]\n",
    "test_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\"]),\n",
    "        AsChannelFirstd(keys=[\"img\"]),\n",
    "        ScaleIntensityd(keys=[\"img\"]),\n",
    "        Resized(keys=[\"img\"], spatial_size=[800, 800]),\n",
    "        EnsureTyped(keys=[\"img\"])\n",
    "    ]\n",
    ")\n",
    "test_ds = monai.data.Dataset(data=test_files, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_ds, batch_size=1,  collate_fn=list_data_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 確認儲存路徑(public)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_path = sorted(glob.glob(tempdir + \"*.jpg\"))\n",
    "pub_path[0].split(\"/\")[-1].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, test_data in enumerate(test_loader):\n",
    "        test_images = test_data[\"img\"].to(device)\n",
    "        \n",
    "        # define sliding window size and batch size for windows inference\n",
    "#         roi_size = (800, 800)\n",
    "#         sw_batch_size = 4\n",
    "#         test_outputs = sliding_window_inference(test_images, roi_size, sw_batch_size, model)\n",
    "\n",
    "        test_outputs, test_out_label = model(test_images) #forward\n",
    "        test_outputs = Resize([-1, 1716, 942])(test_outputs)\n",
    "        \n",
    "        saverPD = SaveImage(output_dir=f\"./{save_path}/output\", output_ext=\".png\", output_postfix=f\"{pub_path[i].split('/')[-1].split('.')[0]}\",scale=255,separate_folder=False)\n",
    "        saverPD(test_outputs[0].cpu())\n",
    "\n",
    "    dice_metric.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdir = \"./Pruvate_image/\"\n",
    "private_images = sorted(glob.glob(os.path.join(tempdir, \"*.jpg\")))\n",
    "\n",
    "\n",
    "print(f\" {len(private_images)} private_images\")\n",
    "\n",
    "private_files = [{\"img\": img} for img in private_images[:]]\n",
    "private_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\"]),        \n",
    "        AsChannelFirstd(keys=[\"img\"]),\n",
    "        ScaleIntensityd(keys=[\"img\"]),\n",
    "        Resized(keys=[\"img\"], spatial_size=[800, 800]),\n",
    "        EnsureTyped(keys=[\"img\"])\n",
    "    ]\n",
    ")\n",
    "test_ds = monai.data.Dataset(data= private_files, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_ds, batch_size=1,  collate_fn=list_data_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pri_path = sorted(glob.glob(tempdir + \"*.jpg\"))\n",
    "pri_path[0].split(\"/\")[-1].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "steppp = 0\n",
    "with torch.no_grad():\n",
    "    for i, test_data in enumerate(test_loader):\n",
    "        test_images = test_data[\"img\"].to(device)\n",
    "        # define sliding window size and batch size for windows inference\n",
    "\n",
    "        test_outputs, test_out_label = model(test_images) #forward\n",
    "        test_outputs = Resize([-1, 1716, 942])(test_outputs)\n",
    "\n",
    "        saverPD = SaveImage(output_dir=f\"./{save_path}/output\", output_ext=\".png\", output_postfix=f\"{pri_path[i].split('/')[-1].split('.')[0]}\",scale=255,separate_folder=False)\n",
    "        saverPD(test_outputs[0].cpu())\n",
    "        \n",
    "        test_outputs = [post_trans(i) for i in decollate_batch(test_outputs)]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict = sorted(glob.glob(f\"./{save_path}/output/*.png\"))\n",
    "predict[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in predict:\n",
    "    os.rename(img, os.path.join(*img.split(\"/\")[:-1], img.split(\"/\")[-1].split(\"_\", 1)[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# zip\n",
    "\n",
    "> if need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !zip -r effnetv2.zip tf_efficientnetv2_m_in21ft1k_ver3/output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
